{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4ZgXOs4uBmG"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45WKXeE0Euse",
        "outputId": "9f853709-63f0-4961-c1b7-6e44f96481af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.3/494.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ],
      "source": [
        "! pip install -q opensmile\n",
        "!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sb5U6fsbF3mD"
      },
      "outputs": [],
      "source": [
        "import opensmile\n",
        "import audiofile\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYc1CkYVnX_5",
        "outputId": "98be611d-f437-427f-fce9-9f777133d6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "kBlpVZTNnhss"
      },
      "outputs": [],
      "source": [
        "SRC_CLEAN = \"drive/MyDrive/idlproj/data/clean/\"\n",
        "SRC_NOISY = \"drive/MyDrive/idlproj/data/auto/\"\n",
        "SRC_ENHAN = \"drive/MyDrive/idlproj/data/enhan_auto_fullsubnet/enhanced_0010/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFJcdLa199iM",
        "outputId": "23ec5a47-92da-458d-af50-0100b0d1f979"
      },
      "outputs": [],
      "source": [
        "#required to be created if files have to be renamed in the noisy and enhanced directory\n",
        "\n",
        "clean_file_map = dict()\n",
        "noisy_file_map = dict()\n",
        "enhan_file_map = dict()\n",
        "\n",
        "for fn in os.listdir(SRC_CLEAN):\n",
        "    identifier = fn.split(\"_\")[-1].split(\".\")[0]\n",
        "    clean_file_map[identifier] = fn\n",
        "\n",
        "for fn in os.listdir(SRC_NOISY):\n",
        "    identifier = fn.split(\"_\")[-1].split(\".\")[0]\n",
        "    noisy_file_map[identifier] = fn\n",
        "\n",
        "for fn in os.listdir(SRC_ENHAN):\n",
        "    identifier = fn.split(\"_\")[-1].split(\".\")[0]\n",
        "    enhan_file_map[identifier] = fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KuDbfL4s9xww"
      },
      "outputs": [],
      "source": [
        "# Loop over the dictionary and rename the files\n",
        "for file_id, old_filename in enhan_file_map.items():\n",
        "    # Construct the old filepath\n",
        "    old_filepath = os.path.join(SRC_ENHAN, old_filename)\n",
        "\n",
        "    # Get the new filename\n",
        "    new_filename = 'enhan_' + file_id + '.wav'\n",
        "\n",
        "    # Construct the new filepath\n",
        "    new_filepath = os.path.join(SRC_ENHAN, new_filename)\n",
        "\n",
        "    # Rename the file\n",
        "    os.rename(old_filepath, new_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "UFPaArSx_Ppq"
      },
      "outputs": [],
      "source": [
        "# Loop over the dictionary and rename the files\n",
        "for file_id, old_filename in noisy_file_map.items():\n",
        "\n",
        "    # Construct the old filepath\n",
        "    old_filepath = os.path.join(SRC_NOISY, old_filename)\n",
        "\n",
        "    # Get the new filename\n",
        "    new_filename = 'auto_' + file_id + '.wav'\n",
        "\n",
        "    # Construct the new filepath\n",
        "    new_filepath = os.path.join(SRC_NOISY, new_filename)\n",
        "\n",
        "    # Rename the file\n",
        "    os.rename(old_filepath, new_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP13Aq5cuFxz"
      },
      "source": [
        "# Calculate Functionals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "T845S9jpE61c"
      },
      "outputs": [],
      "source": [
        "smile = opensmile.Smile(\n",
        "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "    feature_level=opensmile.FeatureLevel.Functionals,\n",
        ")\n",
        "functionals_cols = smile.feature_names\n",
        "functionals = pd.DataFrame(columns = functionals_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks_jGV9Wod4A",
        "outputId": "7d92fe2b-cfe9-4913-885f-2872b01e38db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm', 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0', 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0', 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0', 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2', 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 'loudness_sma3_amean', 'loudness_sma3_stddevNorm', 'loudness_sma3_percentile20.0', 'loudness_sma3_percentile50.0', 'loudness_sma3_percentile80.0', 'loudness_sma3_pctlrange0-2', 'loudness_sma3_meanRisingSlope', 'loudness_sma3_stddevRisingSlope', 'loudness_sma3_meanFallingSlope', 'loudness_sma3_stddevFallingSlope', 'spectralFlux_sma3_amean', 'spectralFlux_sma3_stddevNorm', 'mfcc1_sma3_amean', 'mfcc1_sma3_stddevNorm', 'mfcc2_sma3_amean', 'mfcc2_sma3_stddevNorm', 'mfcc3_sma3_amean', 'mfcc3_sma3_stddevNorm', 'mfcc4_sma3_amean', 'mfcc4_sma3_stddevNorm', 'jitterLocal_sma3nz_amean', 'jitterLocal_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_amean', 'shimmerLocaldB_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_amean', 'HNRdBACF_sma3nz_stddevNorm', 'logRelF0-H1-H2_sma3nz_amean', 'logRelF0-H1-H2_sma3nz_stddevNorm', 'logRelF0-H1-A3_sma3nz_amean', 'logRelF0-H1-A3_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean', 'F1frequency_sma3nz_stddevNorm', 'F1bandwidth_sma3nz_amean', 'F1bandwidth_sma3nz_stddevNorm', 'F1amplitudeLogRelF0_sma3nz_amean', 'F1amplitudeLogRelF0_sma3nz_stddevNorm', 'F2frequency_sma3nz_amean', 'F2frequency_sma3nz_stddevNorm', 'F2bandwidth_sma3nz_amean', 'F2bandwidth_sma3nz_stddevNorm', 'F2amplitudeLogRelF0_sma3nz_amean', 'F2amplitudeLogRelF0_sma3nz_stddevNorm', 'F3frequency_sma3nz_amean', 'F3frequency_sma3nz_stddevNorm', 'F3bandwidth_sma3nz_amean', 'F3bandwidth_sma3nz_stddevNorm', 'F3amplitudeLogRelF0_sma3nz_amean', 'F3amplitudeLogRelF0_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_amean', 'alphaRatioV_sma3nz_stddevNorm', 'hammarbergIndexV_sma3nz_amean', 'hammarbergIndexV_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_amean', 'slopeV0-500_sma3nz_stddevNorm', 'slopeV500-1500_sma3nz_amean', 'slopeV500-1500_sma3nz_stddevNorm', 'spectralFluxV_sma3nz_amean', 'spectralFluxV_sma3nz_stddevNorm', 'mfcc1V_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm', 'mfcc2V_sma3nz_amean', 'mfcc2V_sma3nz_stddevNorm', 'mfcc3V_sma3nz_amean', 'mfcc3V_sma3nz_stddevNorm', 'mfcc4V_sma3nz_amean', 'mfcc4V_sma3nz_stddevNorm', 'alphaRatioUV_sma3nz_amean', 'hammarbergIndexUV_sma3nz_amean', 'slopeUV0-500_sma3nz_amean', 'slopeUV500-1500_sma3nz_amean', 'spectralFluxUV_sma3nz_amean', 'loudnessPeaksPerSec', 'VoicedSegmentsPerSec', 'MeanVoicedSegmentLengthSec', 'StddevVoicedSegmentLengthSec', 'MeanUnvoicedSegmentLength', 'StddevUnvoicedSegmentLength', 'equivalentSoundLevel_dBp']\n"
          ]
        }
      ],
      "source": [
        "print (functionals_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qx9poKCJAut3"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "def get_functionals(dir):  \n",
        "    functionals = pd.DataFrame(columns = functionals_cols)\n",
        "    for file in tqdm(sorted(os.listdir(dir))):\n",
        "        if not file.endswith(\".wav\"):\n",
        "          continue\n",
        "        signal, sampling_rate = audiofile.read(dir + file,\n",
        "          duration=10,\n",
        "          always_2d=True)\n",
        "        \n",
        "        smile = opensmile.Smile(\n",
        "          feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "          feature_level=opensmile.FeatureLevel.Functionals,\n",
        "        )\n",
        "        \n",
        "        res = smile.process_signal(\n",
        "          signal,\n",
        "          sampling_rate\n",
        "        )\n",
        "        res['FileId'] = file\n",
        "\n",
        "        functionals = pd.concat([functionals, res])\n",
        "    \n",
        "    cols = functionals.columns.tolist()\n",
        "    cols = cols[-1:] + cols[:-1]\n",
        "    functionals = functionals[cols]\n",
        "\n",
        "    return functionals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbBMlT4HpyHv",
        "outputId": "add288eb-3b00-4eed-c913-137259490021"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [02:40<00:00,  1.07s/it]\n",
            "100%|██████████| 150/150 [02:37<00:00,  1.05s/it]\n",
            "100%|██████████| 150/150 [02:38<00:00,  1.06s/it]\n"
          ]
        }
      ],
      "source": [
        "clean_functionals = get_functionals(SRC_CLEAN)\n",
        "noisy_functionals = get_functionals(SRC_NOISY)\n",
        "enhan_functionals = get_functionals(SRC_ENHAN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5HMtBi_J6wYp"
      },
      "outputs": [],
      "source": [
        "clean_functionals.to_csv(\"./drive/MyDrive/idlproj/features/clean_functionals.csv\")\n",
        "noisy_functionals.to_csv(\"./drive/MyDrive/idlproj/features/auto_functionals.csv\")\n",
        "enhan_functionals.to_csv(\"./drive/MyDrive/idlproj/features/enhan_auto_functionals.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-IOx9wGuZLl"
      },
      "source": [
        "# Calculate Low level Descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_wXQ5nqpA9td"
      },
      "outputs": [],
      "source": [
        "smile = opensmile.Smile(\n",
        "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",
        ")\n",
        "\n",
        "lowlevel_cols = smile.feature_names\n",
        "lowlevel = pd.DataFrame(columns = lowlevel_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "m3bkreJxBCkI"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "def get_lld(dir):\n",
        "    lowlevel = pd.DataFrame(columns = lowlevel_cols)\n",
        "    for file in tqdm(sorted(os.listdir(dir))):\n",
        "        if not file.endswith(\".wav\"):\n",
        "          continue\n",
        "        signal, sampling_rate = audiofile.read(\n",
        "          dir + file,\n",
        "          duration=10,\n",
        "          always_2d=True\n",
        "        )\n",
        "        \n",
        "        smile = opensmile.Smile(\n",
        "          feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "          feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",
        "        )\n",
        "        \n",
        "        res = smile.process_signal(\n",
        "          signal,\n",
        "          sampling_rate\n",
        "        )\n",
        "        res['FileId'] = file\n",
        "        # print(res.shape)\n",
        "        # break\n",
        "        lowlevel = pd.concat([lowlevel, res])\n",
        "        \n",
        "    cols = lowlevel.columns.tolist()\n",
        "    cols = cols[-1:] + cols[:-1]\n",
        "    lowlevel = lowlevel[cols]\n",
        "\n",
        "    return lowlevel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Jn0P2mCObk",
        "outputId": "14da16ec-b62a-47e4-bc89-01ef1a467ec5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [02:47<00:00,  1.12s/it]\n",
            "100%|██████████| 150/150 [02:39<00:00,  1.06s/it]\n",
            "100%|██████████| 150/150 [02:46<00:00,  1.11s/it]\n"
          ]
        }
      ],
      "source": [
        "clean_lld = get_lld(SRC_CLEAN)\n",
        "noisy_lld = get_lld(SRC_NOISY)\n",
        "enhan_lld = get_lld(SRC_ENHAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xmBF-G4bFAeZ"
      },
      "outputs": [],
      "source": [
        "clean_lld.to_csv(\"./drive/MyDrive/idlproj/features/clean_lld.csv\")\n",
        "noisy_lld.to_csv(\"./drive/MyDrive/idlproj/features/auto_lld.csv\")\n",
        "enhan_lld.to_csv(\"./drive/MyDrive/idlproj/features/enhan_auto_lld.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "tIZx7gz_uXgt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read in data\n",
        "enhan_lld = pd.read_csv(\"./drive/MyDrive/idlproj/features/enhan_auto_lld.csv\"\n",
        "        ).sort_values(['FileId','Unnamed: 0'] # sort by filename and timedelta\n",
        "        #).sort_values(['Unnamed: 0']\n",
        "        ).iloc[:,2:].to_numpy() # don't include index/timedelta/fileid columns\n",
        "\n",
        "\n",
        "### clean ###\n",
        "clean_lld = pd.read_csv(\"./drive/MyDrive/idlproj/features/clean_lld.csv\"\n",
        "        ).sort_values(['FileId','Unnamed: 0'] # sort by filename and timedelta\n",
        "        #).sort_values(['Unnamed: 0']\n",
        "        ).iloc[:,2:].to_numpy() # don't include index/timedelta/fileid columns\n",
        "\n",
        "\n",
        "### noisy ###\n",
        "noisy_lld = pd.read_csv(\"./drive/MyDrive/idlproj/features/auto_lld.csv\"\n",
        "        ).sort_values(['FileId','Unnamed: 0'] # sort by filename and timedelta\n",
        "        #).sort_values(['Unnamed: 0']\n",
        "        ).iloc[:,2:].to_numpy() # don't include index/timedelta/fileid columns\n",
        "\n",
        "# read in data\n",
        "enhan_functionals = pd.read_csv(\"./drive/MyDrive/idlproj/features/enhan_auto_functionals.csv\"\n",
        "        ).sort_values(['Unnamed: 0'] # sort by filename and timedelta\n",
        "        ).iloc[:,2:].to_numpy() # don't include index/timedelta/fileid columns\n",
        "\n",
        "\n",
        "### clean ###\n",
        "clean_functionals = pd.read_csv(\"./drive/MyDrive/idlproj/features/clean_functionals.csv\"\n",
        "        ).sort_values(['Unnamed: 0'] # sort by filename and timedelta\n",
        "        ).iloc[:,2:].to_numpy() # don't include index/timedelta/fileid columns\n",
        "\n",
        "\n",
        "### noisy ###\n",
        "noisy_functionals = pd.read_csv(\"./drive/MyDrive/idlproj/features/auto_functionals.csv\"\n",
        "        ).sort_values(['Unnamed: 0'] # sort by filename and timedelta\n",
        "        ).iloc[:,2:].to_numpy() # don't include index/timedelta/fileid columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "qXFOdhdJUYnt"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_mu(data):\n",
        "    return data.mean(axis=0)\n",
        "\n",
        "def get_std(data):\n",
        "    return data.std(axis=0)\n",
        "\n",
        "def get_standardized(data):\n",
        "    # standardize data i.e. X = (X-MU) / STD\n",
        "    return (data-get_mu(data))/get_std(data)\n",
        "\n",
        "# MAE = lambda x,y: np.mean(np.abs(x-y),axis=0) # edited from konan's func b/c input data shapes differ\n",
        "\n",
        "import sklearn.metrics\n",
        "\n",
        "MAE = sklearn.metrics.mean_absolute_error\n",
        "\n",
        "MAE_lld_enhan = MAE(get_standardized(enhan_lld), get_standardized(clean_lld), multioutput='raw_values')\n",
        "MAE_lld_noisy = MAE(get_standardized(noisy_lld), get_standardized(clean_lld), multioutput='raw_values')\n",
        "\n",
        "MAE_lld_enhan_agg = MAE(get_standardized(enhan_lld), get_standardized(clean_lld))\n",
        "MAE_lld_noisy_agg = MAE(get_standardized(noisy_lld), get_standardized(clean_lld))\n",
        "\n",
        "# calculate improvement \n",
        "I = lambda mae_x, mae_y: (mae_y - mae_x) / mae_y\n",
        "\n",
        "I_lld_enhan_noisy = 100 * I( MAE_lld_enhan , MAE_lld_noisy )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7VI9WRLvTLB",
        "outputId": "4dc74418-bda1-4362-b60b-da5b35c95d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25,)\n"
          ]
        }
      ],
      "source": [
        "print (I_lld_enhan_noisy.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61NNQs2sQKnF",
        "outputId": "d71959b8-63a1-4fa4-ffd2-dc72f5c590b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7175584128313897\n",
            "0.7104335404954505\n"
          ]
        }
      ],
      "source": [
        "# average MAE numbers\n",
        "\n",
        "print (MAE_lld_enhan_agg)\n",
        "print (MAE_lld_noisy_agg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Tfl3HmKzWVmu"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import opensmile\n",
        "import numpy as np\n",
        "import plotly\n",
        "import plotly.subplots\n",
        "import plotly.graph_objects\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# get feature names for low level acoustic\n",
        "LLD = opensmile.Smile(\n",
        "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors)\n",
        "\n",
        "LLD_FEATURE_NAMES = LLD.feature_names\n",
        "\n",
        "def make_plot(I_lld_auto_noisy, filename):\n",
        "  fig = plotly.subplots.make_subplots(rows=1, cols=1, horizontal_spacing=0.01)\n",
        "\n",
        "  ORDER = np.argsort(I_lld_auto_noisy)\n",
        "  FEATURES = [LLD_FEATURE_NAMES[i].split(\"_\")[0] for i in ORDER]\n",
        "\n",
        "  fig.append_trace(\n",
        "      row=1, col=1,\n",
        "      trace = plotly.graph_objects.Bar(\n",
        "          y=FEATURES, \n",
        "          x=I_lld_auto_noisy[ORDER], \n",
        "          orientation='h', name=f\"FSN {filename} Improvement Over Auto\"))\n",
        "\n",
        "  HEIGHT = 290\n",
        "  WIDTH  = 370\n",
        "\n",
        "  fig.update_yaxes(showticklabels=False, col=2)\n",
        "  fig.update_layout(\n",
        "      height = 3*HEIGHT, \n",
        "      width  = 3*WIDTH,\n",
        "      legend=dict(orientation=\"h\", yanchor=\"bottom\"),\n",
        "      margin = dict(l=0, r=0, t=0, b=0),\n",
        "      bargap =0.50,\n",
        "      # xaxis1_range=[-70,100],\n",
        "      xaxis1_range=[I_lld_auto_noisy.min()-5,I_lld_auto_noisy.max()+5],\n",
        "      xaxis1=dict(tickmode='linear', dtick=20)\n",
        "  )\n",
        "\n",
        "  FONT_FAMILY = \"Times New Roman\"\n",
        "  FONT_SIZE   = 9\n",
        "\n",
        "  keys = list(locals().keys())\n",
        "  for l in keys:\n",
        "      if l[:3] == 'fig':\n",
        "          locals()[l].update_layout(font_family=FONT_FAMILY, font_size = 2*FONT_SIZE)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "  fig.write_image(\"drive/MyDrive/idlproj/Auto LLD Improvment.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "dSGOAPrTWuqL",
        "outputId": "08b5edf0-027b-487f-b98d-c7a2d8cf3755"
      },
      "outputs": [],
      "source": [
        "make_plot(I_lld_enhan_noisy, \"LLD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "zniGNrJYvn6i"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_mu(data):\n",
        "    return data.mean(axis=0)\n",
        "\n",
        "def get_std(data):\n",
        "    return data.std(axis=0)\n",
        "\n",
        "def get_standardized(data):\n",
        "    # standardize data i.e. X = (X-MU) / STD\n",
        "    return (data-get_mu(data))/get_std(data)\n",
        "\n",
        "# MAE = lambda x,y: np.mean(np.abs(x-y),axis=0) # edited from konan's func b/c input data shapes differ\n",
        "\n",
        "import sklearn.metrics\n",
        "\n",
        "MAE = sklearn.metrics.mean_absolute_error\n",
        "\n",
        "MAE_functionals_enhan = MAE(get_standardized(enhan_functionals), get_standardized(clean_functionals), multioutput='raw_values')\n",
        "MAE_functionals_noisy = MAE(get_standardized(noisy_functionals), get_standardized(clean_functionals), multioutput='raw_values')\n",
        "\n",
        "MAE_functionals_enhan_agg = MAE(get_standardized(enhan_functionals), get_standardized(clean_functionals))\n",
        "MAE_functionals_noisy_agg = MAE(get_standardized(noisy_functionals), get_standardized(clean_functionals))\n",
        "\n",
        "# calculate improvement \n",
        "I = lambda mae_x, mae_y: (mae_y - mae_x) / mae_y\n",
        "\n",
        "I_functionals_enhan_noisy = 100 * I( MAE_functionals_enhan , MAE_functionals_noisy )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1sCmvz0wj5I",
        "outputId": "614264f0-d59b-44f7-d558-1e105f133100"
      },
      "outputs": [],
      "source": [
        "print (I_functionals_enhan_noisy.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIjkSQYzzRid",
        "outputId": "3ae84a84-44fe-467d-ef50-32853bb150df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7429446566017095\n",
            "0.6967222054562329\n"
          ]
        }
      ],
      "source": [
        "# average MAE numbers\n",
        "\n",
        "print (MAE_functionals_enhan_agg)\n",
        "print (MAE_functionals_noisy_agg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "NnscMSUhwp6y"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import opensmile\n",
        "import numpy as np\n",
        "import plotly\n",
        "import plotly.subplots\n",
        "import plotly.graph_objects\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# get feature names for low level acoustic\n",
        "functionals = opensmile.Smile(\n",
        "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "    feature_level=opensmile.FeatureLevel.Functionals)\n",
        "\n",
        "FUNCTIONALS_FEATURE_NAMES = functionals.feature_names\n",
        "\n",
        "def make_plot(I_functionals_auto_noisy, filename):\n",
        "  fig = plotly.subplots.make_subplots(rows=1, cols=1, horizontal_spacing=0.01)\n",
        "\n",
        "  ORDER = np.argsort(I_functionals_auto_noisy)\n",
        "  #FEATURES = [FUNCTIONALS_FEATURE_NAMES[i].split(\"_\")[0] for i in ORDER]\n",
        "  FEATURES = [FUNCTIONALS_FEATURE_NAMES[i] for i in ORDER]\n",
        "\n",
        "  print (FEATURES)\n",
        "\n",
        "  fig.append_trace(\n",
        "      row=1, col=1,\n",
        "      trace = plotly.graph_objects.Bar(\n",
        "          y=FEATURES, \n",
        "          x=I_functionals_auto_noisy[ORDER], \n",
        "          orientation='h', name=f\"FSN {filename} Improvement Over Auto\"))\n",
        "\n",
        "  HEIGHT = 400\n",
        "  WIDTH  = 370\n",
        "\n",
        "  fig.update_yaxes(showticklabels=True, col=2)\n",
        "  fig.update_layout(\n",
        "      height = 3*HEIGHT, \n",
        "      width  = 3*WIDTH,\n",
        "      legend=dict(orientation=\"h\", yanchor=\"bottom\"),\n",
        "      margin = dict(l=0, r=0, t=0, b=0),\n",
        "      bargap =0.50,\n",
        "      # xaxis1_range=[-70,100],\n",
        "      xaxis1_range=[I_functionals_auto_noisy.min()-5,I_functionals_auto_noisy.max()+5],\n",
        "      xaxis1=dict(tickmode='linear', dtick=20)\n",
        "  )\n",
        "\n",
        "  FONT_FAMILY = \"Times New Roman\"\n",
        "  FONT_SIZE   = 4\n",
        "\n",
        "  keys = list(locals().keys())\n",
        "  for l in keys:\n",
        "      if l[:3] == 'fig':\n",
        "          locals()[l].update_layout(font_family=FONT_FAMILY, font_size = 2*FONT_SIZE)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "  fig.write_image(\"drive/MyDrive/idlproj/Auto Functionals Improvement.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JtqbfyLsyQAO",
        "outputId": "b3ea8b75-8367-44bb-d67b-55d61d4f18bd"
      },
      "outputs": [],
      "source": [
        "make_plot(I_functionals_enhan_noisy, \"Functionals\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "t4ZgXOs4uBmG",
        "fkNzUAoDuhct",
        "EP13Aq5cuFxz",
        "6-IOx9wGuZLl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
